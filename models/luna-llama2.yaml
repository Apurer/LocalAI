backend: llama
context_size: 2000
f16: true
gpu_layers: 4
name: lunademo
parameters:
  model: luna-ai-llama2-uncensored.Q4_K_M.gguf
  temperature: 0.2
  top_k: 40
  top_p: 0.65
stopwords:
- "HUMAN:"
- "GPT:"
roles:
  user: " "
  system: " "
template:
  chat: luna-llama2-chat
  completion: luna-llama2-completion